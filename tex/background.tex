%!TEX root = thesis.tex

\chapter{Background}

\section{History of Social Choice Theory}

	Voting systems are not a recent invention---they have been around in one form or another for thousands of years. The earliest democracies resembling what we use today date back to around 508 BC in Athens, Greece, and the general idea of elections was used even before that in many other parts of the world \cite{democracybritannica}. In Athens, the assembly was the core of democracy, and any male citizen of at least eighteen years of age was allowed to attend and to vote \cite{heinemann1952}. Athenians voted directly on public policy, instead of electing representatives, and voting was done by majority rule. Voting was also used outside of the assembly in a process known as ostracism which was used to exile individuals if necessary. This was done using the plurality voting rule, whereby each man wrote a name on a piece of pottery and the person with the most votes was exiled \cite{oturnbull}.

	Both the majority rule and the plurality systems used in early Greek democracy were very simple. One drawback of these systems is that each voter can only cast a vote for a single candidate even if, for example, there are two candidates that he thinks are very good. In reality a voter usually does not like one candidate and hate all the others, but usually likes various candidates to different degrees. Therefore, a more accurate way to represent each voter's opinion is with a ranked list of all the candidates, which in social choice theory is called a preference list.

	In more recent centuries, voting has taken great strides forward from the simpler methods used in ancient Greece. In 1770, Jean-Charles de Borda proposed a voting system, known now as the Borda count, as a way of electing members of the French Academy of Sciences \cite{borda1781mémoire}. As a side note, although the voting system is named after Borda, it has recently been discovered that Ramon Llull independently invented the same system even earlier---in the 13th century \cite{hägele2001llull}. In the Borda count system, each candidate receives points based on his rank in each voter's preference list, i.e., a candidate will get the most points for each first place ranking, he will get slightly fewer points for each second place ranking, and so on. The winning candidate is the one who receives the greatest total number of points. It was around the time Borda proposed this system that voting systems began to be studied academically.

	Majority rule, plurality, and the Borda count are a few examples of voting systems, but there are many others. Given the large number of voting systems, and that each system seems to have various strengths and weaknesses, it is useful to compare them to each other. The most obvious criterion for a good voting system is fairness \cite{chevaleyre2006issues}. It seems natural that the best voting system is the one which best represents the constituents' preferences. Fairness of a voting system is easy to recognize if there are only two candidates: the candidate who is preferred by the majority of voters should win. But with a larger number of candidates, determining the fairness of a voting system is not so obvious.

	Interest in the fairness of voting systems prompted Marquis de Condorcet, a contemporary of Borda, to propose that the winning candidate of an election be the candidate who would win a head-to-head election against each of the other candidates (he proposed this in the year 1785). Such a winner is known as the \emph{Condorcet winner}. Unfortunately, Condorcet also proved that a Condorcet winner does not always exist because majority preferences are intransitive in elections with more than two alternatives \cite{le1785essai, black1998theory}. In other words, it is possible to have alternative $a \succ $(beats)$ b$, $b \succ c$, $c \succ a$. A voting system that gives the Condorcet winner if one exists is said to satisfy the \emph{Condorcet criterion}. The Condorcet criterion was one of the first formal fairness criteria, and is still widely used today.

	In 1876, Charles Dodgson (also known as Lewis Carroll) proposed a voting system, satisfying the Condorcet criterion, known as Dodgson's method. Dodgson's method declares the winner to be whichever alternative can become a Condorcet winner with the fewest adjacent swaps in voters' preference lists \cite{dodgson1876method}. More precisely, given the original profile $p$, we select a profile $p'$ such that $p'$ has a Condorcet winner and the total Kendall tau distance (see Definition \ref{kendall-tau-definition}) between $p$ and $p'$ is minimum (compared to all possible profiles). Then the winner is the alternative that wins under $p'$. One major drawback of this method is that computing the winner is NP-hard \cite{bartholdi1989voting}.

	In 1950, an American economist named Kenneth Arrow made a large contribution to the field of Social Choice Theory with his impossibility theorem. Arrow was interested in the fairness of social welfare functions, which are similar to the social choice functions except that instead of a single winner, they yield a full ranking of all alternatives. Arrow's theorem \cite{arrow1950difficulty} (which he strengthened in 1963 \cite{arrow1963social}) demonstrates that no social welfare function can ``fairly'' convert the preferences of voters into a society-wide preference list. While ``fair'' is clearly subjective, he gave a list of basic properties which seem intuitively required for fairness:
	\begin{description}
		\item[Unrestricted domain (universality)] All individual preferences are allowed and yield a valid group preference.
		\item[Independence of irrelevant alternatives] If all voters' preferences between alternatives $x$ and $y$ remain the same, the group preference between $x$ and $y$ is unchanged even if voters change their preferences regarding other alternatives.
		\item[Pareto principle (unanimity)] Unanimity of individual preferences implies a group preference. E.g. if all individuals prefer alternative $x$ to $y$, then the group will prefer $x$ to $y$.
		\item[Non-dictatorship] There is no voter whose preference always dictates the group's preference.
	\end{description}
	Arrow proved that these properties are inconsistent: no social welfare function can satisfy all of these properties, hence, no social welfare function can be completely fair.

	The work done by Condorcet and Arrow is widely regarded as being foundational to the modern field of social choice theory, and marks a transition from viewing social choice as a purely practical problem to a more rigorous theoretical study.


\section{History of Manipulation}

	One problem relating to the issue of fairness in social choice theory is that of manipulation (or strategic voting or tactical voting). Manipulation is when an individual purposefully misrepresents his preferences hoping to get a more favorable outcome in the election. For example, if a voter knows that his most preferred alternative has no chance of winning the election, he may instead say that he prefers a different alternative, so that even though his favorite alternative cannot win, at least his second choice alternative has a better chance of winning. For a formal definition of manipulation, see Definition \ref{manipulation-definition}. Manipulation will benefit the voter but will not benefit the society in general, because by lying about his preferences the voter has skewed the results of the election in his favor. Therefore, it is beneficial to search for ways to avoid manipulation in social choice.

	One way to avoid manipulation would be to devise a voting rule that is non-manipulable. Unfortunately, in 1973 the Gibbard-Satterthwaite theorem was published which states that every voting rule satisfying the following properties is subject to manipulation.
	\begin{description}
		\item[Non-dictatorship] There is no voter whose preference always dictates the group preference.
		\item[Non-imposition] Every alternative has the possibility of winning.
	\end{description}
	It would certainly seem that any reasonable voting rule would need to satisfy both of these criteria, hence, any reasonable voting rule is manipulable \cite{gibbard1973manipulation, satterthwaite1975strategy, duggan2000strategic}. This means that we cannot make manipulation impossible via a cleverly devised voting rule---a rather disappointing conclusion.

	Until this point in its history, social choice theory had been separate from computer science---and computer science was a very young discipline at this point. But around this time a new sub-field of social choice theory was spawned: computational social choice theory, which seeks to use computer science to solve problems in social choice theory \cite{chevaleyre2007short}. In 1989, Bartholdi, Tovey, and Trick proposed a computational barrier to manipulation in voting systems \cite{bartholdi1989computational}: instead of trying to make manipulation impossible, they endeavored to make it computationally intractable. Even if a profitable manipulation exists, it is of no practical use  if it is computationally infeasible to find. They were able to demonstrate that while many voting rules are easy to manipulate (a manipulation can be found in polynomial time), the problem of finding a manipulation for certain scoring rules is NP-complete. They called rules that can be manipulated in polynomial time \emph{vulnerable}, and those for which manipulation is NP-hard \emph{resistant}.

	This research paved the way for approaching social choice problems from a computational footing. Bartholdi, Tovey, and Trick also studied the computational difficulty of finding a winner for various voting rules. For example, they showed that the Dodgson method mentioned above \cite{dodgson1876method} is actually infeasible to manipulate for the simple reason that figuring out the winner of the election is NP-hard. Therefore, it is not sufficient for a desirable voting rule to be hard to manipulate; it must also be also be efficient to determine a winner.

	In 1991, Bartholdi and Orlin \cite{bartholdi1991single} added to the above results by showing that the Single Transferable Vote (STV) rule was both resistant to manipulation, and quick to determine a winner. Although STV has problems of its own \cite{brams1982ams, doron1977single, fishburn1983paradoxes, holzman1989vote, moulin1988condorcet}, it is encouraging to see that it is possible for an efficient voting rule to resist manipulation.

	In 2002, Conitzer and Sandholm took a slightly different approach \cite{conitzer2002vote} (which they later extended \cite{conitzer2007elections}), studying coalition manipulation. Instead of a single voter manipulating an election, a group (coalition) of voters work together to manipulate an election. This vein of research has since been extended in various directions \cite{conitzer2003universal, elkind2005hybrid, faliszewski2006complexity, hemaspaandra2007anyone, procaccia2007multi, elkind2005small}.

	The work mentioned so far which attempts to erect a computational barrier to manipulation is encouraging, and may indeed provide ways to prevent manipulation in voting systems. However, it deals with the worst-case complexity of manipulation. In 2006, work by Conitzer and Sandholm \cite{conitzer2006nonexistence} along with that of Procaccia and Rosenschein \cite{procaccia2006junta} showed that some manipulations that are NP-hard in the worst-case, are tractable in the average-case (using distributions that would appear to make manipulation more difficult). In the next few years more work was done to make this concern even more well-founded \cite{procaccia2007average, erdelyi2007approximating}. Work along these lines by Friedgut, Kalai, and Nisan \cite{friedgut2008elections} in 2008, is the main inspiration for this thesis, and has also spawned other work which will be discussed further in the Related Work chapter.
